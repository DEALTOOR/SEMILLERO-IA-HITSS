{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMIB8KX1AsVVFeR8+Jvtl9W",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DEALTOOR/SEMILLERO-IA-HITSS/blob/main/Clase_5_Diego_Torres.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# VP, VN, FP, FN\n",
        "### VP\n",
        "Casos donde la predicción es 1 y el valor real es 1.\n",
        "### VN\n",
        "Casos donde la predicción es 0 y el valor real es 0.\n",
        "### FP\n",
        "Casos donde la predicción es 1 y el valor real es 0.\n",
        "### FN\n",
        "Casos donde la predicción es 0 y el valor real es 1.\n",
        "\n",
        "---\n",
        "# Métricas para conjuntos balanceados\n",
        "Un conjunto balanceado se da cuando hay aproximadamente la misma cantidad de casos positivos y negativos.\n",
        "### *Accuracy* (Exactitud)\n",
        "$Exac = \\frac{VP + VN}{VP + VN + FP + FN}$\n",
        "\n",
        "Mide el porcentaje total de predicciones correctas (positivas o negativas) sobre todos los casos.\n",
        "\n",
        "Se usa cuando las clases están balanceadas (más o menos la misma cantidad de positivos y negativos).\n",
        "### *Specificity* (Especificidad)\n",
        "$Spec=\\frac{VN}{VN + FP}$\n",
        "\n",
        "De todos los casos realmente negativos, mide cuántos fueron correctamente identificados como negativos.\n",
        "\n",
        "Se usa cuando es importante evitar falsos positivos, como en pruebas médicas costosas o alarmas falsas en seguridad.\n",
        "### *Precision* (Precisión)\n",
        "$Precision=\\frac{VP}{VP + FP}$\n",
        "\n",
        "De todas las veces que el modelo predijo “positivo”, mide qué proporción fue correcta.\n",
        "\n",
        "Se usa cuando el costo de un falso positivo es alto (ej. acusar a un correo legítimo de ser spam, diagnosticar erróneamente una enfermedad).\n",
        "\n",
        "---\n",
        "# Métricas para conjuntos no balanceados\n",
        "Cuando hay muchos más casos de una clase que de otra (por ejemplo, 99% negativos y 1% positivos), las métricas anteriores pueden ser engañosas.\n",
        "\n",
        "En esos casos, usamos métricas que ponderan o equilibran el impacto de los errores en la clase minoritaria.\n",
        "### *Recall* (Sensibilidad)\n",
        "$Recall=\\frac{VP}{VP + FN}$\n",
        "\n",
        "De todos los casos que eran realmente positivos, mide qué porcentaje detectó correctamente el modelo.\n",
        "\n",
        "Se usa cuando no queremos perder ningún positivo real, como en diagnóstico médico o detección de fraude.\n",
        "\n",
        "### F1 Score\n",
        "$F1=2*\\frac{Precision * Recall}{Precision + Recall}$\n",
        "\n",
        "Combina precisión y recall en una sola métrica.\n",
        "Castiga los modelos que tienen una de las dos muy baja.\n",
        "\n",
        "Se usa cuando hay clases desbalanceadas y se necesita un equilibrio entre no perder positivos y no generar falsos positivos.\n",
        "\n",
        "### Fβ Score (Generalización de F1)\n",
        "$F_β=(1+β^2)*\\frac{Precision * Recall}{(β^2 * Precision) + Recall}$\n",
        "\n",
        "Permite ajustar la importancia que le das al recall o a la precisión:\n",
        "\n",
        "Si β > 1, se da más peso al recall (importa más no perder positivos reales).\n",
        "\n",
        "Si β < 1, se da más peso a la precisión (importa más no clasificar mal).\n",
        "\n",
        "Se usa cuando queremos personalizar la prioridad entre precisión y recall según el contexto del problema.\n",
        "\n",
        "### F2 Score\n",
        "$F2=5*\\frac{Precision * Recall}{4*Precision + Recall}$\n",
        "\n",
        "Minimiza los Falsos Negativos\n",
        "Se usa cuando es mucho más grave no detectar un positivo que equivocarse clasificando un negativo (por ejemplo, detección de cáncer, fraudes, etc.)."
      ],
      "metadata": {
        "id": "DmI3UHtO3Ae7"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3n2CwueQKPse"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}